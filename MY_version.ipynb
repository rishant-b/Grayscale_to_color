{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7ed24b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Conv2DTranspose, UpSampling2D\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten, InputLayer\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import array_to_img, img_to_array, load_img\n",
    "from skimage.color import rgb2lab, lab2rgb, rgb2gray\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dbaa476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get images\n",
    "X = []\n",
    "for filename in os.listdir(r\"C:\\Users\\risha\\Documents\\Project_X\\Coloring-greyscale-images-master\\Full-version\\Train\\\\\"):\n",
    "    X.append(img_to_array(load_img(r\"C:\\Users\\risha\\Documents\\Project_X\\Coloring-greyscale-images-master\\Full-version\\Train\\\\\"+filename)))\n",
    "X = np.array(X, dtype=float)\n",
    "\n",
    "# Set up train and test data\n",
    "split = int(0.95*len(X))\n",
    "Xtrain = X[:split]\n",
    "Xtrain = 1.0/255*Xtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e76ea870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 256, 256, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "316e7f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(256, 256, 1)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same', strides=2))\n",
    "model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='tanh', padding='same'))\n",
    "model.add(UpSampling2D((2, 2)))\n",
    "model.compile(optimizer='rmsprop', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bc00026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\risha\\AppData\\Local\\Temp\\ipykernel_12548\\3651549848.py:19: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=50, steps_per_epoch=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0056\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0053\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.0055\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0056\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0055\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0055\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0053\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.0061\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.0054\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0055\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0053\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0053\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0056\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0057\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0056\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0053\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0053\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0053\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0052\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0052\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0056\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0053\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0051\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0054\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0052\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0053\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0050\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0050\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 25s 3s/step - loss: 0.0048\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 1233s 2s/step - loss: 0.0055\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 24s 2s/step - loss: 0.0050\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.0050\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0051\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0045\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0047\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0046\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0049\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0046\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0045\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0045\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.0046\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0046\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0042\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0048\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0041\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0043\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0042\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.0037\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.0042\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.0041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12ca0365940>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Image transformer\n",
    "datagen = ImageDataGenerator(\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        rotation_range=30,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "# Generate training data\n",
    "batch_size = 10\n",
    "def image_a_b_gen(batch_size):\n",
    "    for batch in datagen.flow(Xtrain, batch_size=batch_size):\n",
    "        lab_batch = rgb2lab(batch)\n",
    "        X_batch = lab_batch[:,:,:,0]\n",
    "        Y_batch = lab_batch[:,:,:,1:] / 128\n",
    "        yield (X_batch.reshape(X_batch.shape+(1,)), Y_batch)\n",
    "\n",
    "# Train model      \n",
    "tensorboard = TensorBoard(log_dir=\"output/first_run\")\n",
    "model.fit_generator(image_a_b_gen(batch_size), callbacks=[tensorboard], epochs=50, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "853cfb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dc141a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step - loss: 0.0039\n",
      "0.003907251171767712\n"
     ]
    }
   ],
   "source": [
    "# Test images\n",
    "Xtest = rgb2lab(1.0/255*X[split:])[:,:,:,0]\n",
    "Xtest = Xtest.reshape(Xtest.shape+(1,))\n",
    "Ytest = rgb2lab(1.0/255*X[split:])[:,:,:,1:]\n",
    "Ytest = Ytest / 128\n",
    "print(model.evaluate(Xtest, Ytest, batch_size=batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0c8fd757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 408ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from float64 to uint8. Range [0, 1]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "color_me = []\n",
    "for filename in os.listdir(r\"C:\\Users\\risha\\Documents\\Project_X\\Coloring-greyscale-images-master\\Full-version\\Test\\\\\"):\n",
    "    color_me.append(img_to_array(load_img(r\"C:\\Users\\risha\\Documents\\Project_X\\Coloring-greyscale-images-master\\Full-version\\Test\\\\\"+filename)))\n",
    "color_me = np.array(color_me, dtype=float)\n",
    "color_me = rgb2lab(1.0/255*color_me)[:,:,:,0]\n",
    "color_me = color_me.reshape(color_me.shape+(1,))\n",
    "\n",
    "# Test model\n",
    "output = model.predict(color_me)\n",
    "output = output * 128\n",
    "\n",
    "# Output colorizations\n",
    "for i in range(len(output)):\n",
    "    cur = np.zeros((256, 256, 3))\n",
    "    cur[:,:,0] = color_me[i][:,:,0]\n",
    "    cur[:,:,1:] = output[i]\n",
    "    imsave(\"result/img_\"+str(i)+\".png\", lab2rgb(cur))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8bccd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
